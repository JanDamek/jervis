# Logging level configuration
logging:
  level:
    root: INFO
    com.jervis: DEBUG
    org.springframework.web: INFO
    org.springframework.web.filter.CommonsRequestLoggingFilter: INFO
    com.jervis.config.RequestLoggingFilterConfig: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/jervis-app.log
  logback:
    rollingpolicy:
      max-file-size: 1024MB
      max-history: 7

spring:
  data:
    mongodb:
      host: 192.168.100.117
      port: 27017
      database: jervis
      # Uncomment and set these for production with authentication
      username: root
      password: qusre5-mYfpox-dikpef
      authentication-database: admin

# Qdrant vector database configuration
qdrant:
  host: 192.168.100.117
  port: 6334

server:
  port: 5500

models: # embedding is only 762 dimensions
  EMBEDDING_TEXT:
    - provider: LM_STUDIO
      model: text-embedding-nomic-embed-text-v2-moe
      maxTokens: 512
      maxInputTokens: 512
      maxRequests: 12
  #    - provider: OLLAMA
  #      model: text-embedding-nomic-embed-text-v2-moe
  #      maxTokens: 512
  #      maxInputTokens: 512
  #      maxRequests: 8

  EMBEDDING_CODE:
    - provider: LM_STUDIO
      model: nomic-embed-code
      maxTokens: 4096
      maxInputTokens: 4096
      maxRequests: 4
  #    - provider: OLLAMA
  #      model: nomic-embed-code
  #      maxTokens: 4096
  #      maxInputTokens: 4096
  #      maxRequests: 8

  TRANSLATION:
    - provider: LM_STUDIO
      model: deepseek-coder-v2-lite-instruct
      maxTokens: 9196
      maxRequests: 2
    - provider: OLLAMA
      model: deepseek-coder-v2:latest
      maxTokens: 4096
      maxRequests: 2

  RAG:
    - provider: LM_STUDIO
      model: deepseek-coder-v2-lite-instruct
      maxTokens: 9196
      maxRequests: 2
    - provider: OLLAMA
      model: deepseek-coder-v2:latest
      maxTokens: 4096
      maxRequests: 2
    - provider: OPENAI
      model: gpt-4o
      maxTokens: 8196
      maxRequests: 24
    - provider: ANTHROPIC
      model: claude-3-5-sonnet
      maxTokens: 8196
      maxRequests: 30

  INTERNAL:
    - provider: LM_STUDIO
      model: deepseek-coder-v2-lite-instruct
      maxTokens: 9196
      maxRequests: 2
    - provider: OLLAMA
      model: deepseek-coder-v2:latest
      maxTokens: 163986
      maxRequests: 1
    - provider: OLLAMA
      model: llama3.1:8b-instruct-q4_K_M
      maxTokens: 4096
      maxRequests: 2
    - provider: OPENAI
      model: gpt-4o
      maxTokens: 8196
      maxRequests: 24
    - provider: ANTHROPIC
      model: claude-3-5-sonnet
      maxTokens: 8196
      maxRequests: 30

  SPEECH:
    - provider: LM_STUDIO
      model: deepseek-coder-v2-lite-instruct
      maxTokens: 9196
      maxRequests: 2
    - provider: OLLAMA
      model: deepseek-coder-v2:latest
      maxTokens: 163986
      maxRequests: 1
    - provider: OLLAMA
      model: llama3.1:8b-instruct-q4_K_M
      maxTokens: 4096
      maxRequests: 2
    - provider: OPENAI
      model: gpt-4o
      maxTokens: 8196
      maxRequests: 24
    - provider: ANTHROPIC
      model: claude-3-5-sonnet
      maxTokens: 8196
      maxRequests: 30

  CHAT_INTERNAL:
    - provider: LM_STUDIO
      model: deepseek-coder-v2-lite-instruct
      maxTokens: 9196
      maxRequests: 2
    - provider: OLLAMA
      model: deepseek-coder-v2:latest
      maxTokens: 163986
      maxRequests: 1
    - provider: OLLAMA
      model: llama3.1:8b-instruct-q4_K_M
      maxTokens: 4096
      maxRequests: 2
    - provider: OPENAI
      model: gpt-4o
      maxTokens: 8196
      maxRequests: 24
    - provider: ANTHROPIC
      model: claude-3-5-sonnet
      maxTokens: 8196
      maxRequests: 30

  CHAT_EXTERNAL:
    - provider: OPENAI
      model: gpt-4o
      maxTokens: 8196
      maxRequests: 24
    - provider: ANTHROPIC
      model: claude-3-5-sonnet
      maxTokens: 8196
      maxRequests: 30

endpoints:
  openai:
    apiKey: ${OPENAI_API_KEY:}
  anthropic:
    apiKey: ${ANTHROPIC_API_KEY:}
  ollama:
    baseUrl: ${OLLAMA_BASE_URL:http://192.168.100.117:11434/}
  lmStudio:
    baseUrl: ${LMSTUDIO_BASE_URL:http://192.168.101.249:1234/}
